{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"https://raw.githubusercontent.com/sunnysavita10/credit_card_pw_hindi/main/creditCardFraud_28011964_120214.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"./data/data.csv\",index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=[280000,1,1,1,41,-2,-2,-2,-2,-1,0,28026,41302,51500,35752,3955,13969,41346,52110,35752,3955,13939,4437,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>35752</td>\n",
       "      <td>3955</td>\n",
       "      <td>13969</td>\n",
       "      <td>41346</td>\n",
       "      <td>52110</td>\n",
       "      <td>35752</td>\n",
       "      <td>3955</td>\n",
       "      <td>13939</td>\n",
       "      <td>4437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1   2   3   4   5   6   7   8   9   ...     14    15     16     17  \\\n",
       "0  280000   1   1   1  41  -2  -2  -2  -2  -1  ...  35752  3955  13969  41346   \n",
       "\n",
       "      18     19    20     21    22  23  \n",
       "0  52110  35752  3955  13939  4437   0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>35752</td>\n",
       "      <td>3955</td>\n",
       "      <td>13969</td>\n",
       "      <td>41346</td>\n",
       "      <td>52110</td>\n",
       "      <td>35752</td>\n",
       "      <td>3955</td>\n",
       "      <td>13939</td>\n",
       "      <td>4437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0     280000    1          1         1   41     -2     -2     -2     -2   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -1  ...      35752       3955      13969     41346     52110     35752   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0      3955     13939      4437                           0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIMIT_BAL                     int64\n",
       "SEX                           int64\n",
       "EDUCATION                     int64\n",
       "MARRIAGE                      int64\n",
       "AGE                           int64\n",
       "PAY_0                         int64\n",
       "PAY_2                         int64\n",
       "PAY_3                         int64\n",
       "PAY_4                         int64\n",
       "PAY_5                         int64\n",
       "PAY_6                         int64\n",
       "BILL_AMT1                     int64\n",
       "BILL_AMT2                     int64\n",
       "BILL_AMT3                     int64\n",
       "BILL_AMT4                     int64\n",
       "BILL_AMT5                     int64\n",
       "BILL_AMT6                     int64\n",
       "PAY_AMT1                      int64\n",
       "PAY_AMT2                      int64\n",
       "PAY_AMT3                      int64\n",
       "PAY_AMT4                      int64\n",
       "PAY_AMT5                      int64\n",
       "PAY_AMT6                      int64\n",
       "default payment next month    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19394</td>\n",
       "      <td>19619</td>\n",
       "      <td>20024</td>\n",
       "      <td>2500</td>\n",
       "      <td>1815</td>\n",
       "      <td>657</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>542653</td>\n",
       "      <td>483003</td>\n",
       "      <td>473944</td>\n",
       "      <td>55000</td>\n",
       "      <td>40000</td>\n",
       "      <td>38000</td>\n",
       "      <td>20239</td>\n",
       "      <td>13750</td>\n",
       "      <td>13770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>-159</td>\n",
       "      <td>567</td>\n",
       "      <td>380</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>1687</td>\n",
       "      <td>1542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12211</td>\n",
       "      <td>11793</td>\n",
       "      <td>3719</td>\n",
       "      <td>3329</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      50000    1          2         1   57     -1      0     -1      0   \n",
       "1      50000    1          1         2   37      0      0      0      0   \n",
       "2     500000    1          1         2   29      0      0      0      0   \n",
       "3     100000    2          2         2   23      0     -1     -1      0   \n",
       "4     140000    2          3         1   28      0      0      2      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "1      0  ...      19394      19619      20024      2500      1815       657   \n",
       "2      0  ...     542653     483003     473944     55000     40000     38000   \n",
       "3      0  ...        221       -159        567       380       601         0   \n",
       "4      0  ...      12211      11793       3719      3329         0       432   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0      9000       689       679                           0  \n",
       "1      1000      1000       800                           0  \n",
       "2     20239     13750     13770                           0  \n",
       "3       581      1687      1542                           0  \n",
       "4      1000      1000      1000                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIMIT_BAL                     0\n",
       "SEX                           0\n",
       "EDUCATION                     0\n",
       "MARRIAGE                      0\n",
       "AGE                           0\n",
       "PAY_0                         0\n",
       "PAY_2                         0\n",
       "PAY_3                         0\n",
       "PAY_4                         0\n",
       "PAY_5                         0\n",
       "PAY_6                         0\n",
       "BILL_AMT1                     0\n",
       "BILL_AMT2                     0\n",
       "BILL_AMT3                     0\n",
       "BILL_AMT4                     0\n",
       "BILL_AMT5                     0\n",
       "BILL_AMT6                     0\n",
       "PAY_AMT1                      0\n",
       "PAY_AMT2                      0\n",
       "PAY_AMT3                      0\n",
       "PAY_AMT4                      0\n",
       "PAY_AMT5                      0\n",
       "PAY_AMT6                      0\n",
       "default payment next month    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- no null values are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default payment next month\n",
       "0    787\n",
       "1    214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['default payment next month'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 24 columns):\n",
      " #   Column                      Non-Null Count  Dtype\n",
      "---  ------                      --------------  -----\n",
      " 0   LIMIT_BAL                   1001 non-null   int64\n",
      " 1   SEX                         1001 non-null   int64\n",
      " 2   EDUCATION                   1001 non-null   int64\n",
      " 3   MARRIAGE                    1001 non-null   int64\n",
      " 4   AGE                         1001 non-null   int64\n",
      " 5   PAY_0                       1001 non-null   int64\n",
      " 6   PAY_2                       1001 non-null   int64\n",
      " 7   PAY_3                       1001 non-null   int64\n",
      " 8   PAY_4                       1001 non-null   int64\n",
      " 9   PAY_5                       1001 non-null   int64\n",
      " 10  PAY_6                       1001 non-null   int64\n",
      " 11  BILL_AMT1                   1001 non-null   int64\n",
      " 12  BILL_AMT2                   1001 non-null   int64\n",
      " 13  BILL_AMT3                   1001 non-null   int64\n",
      " 14  BILL_AMT4                   1001 non-null   int64\n",
      " 15  BILL_AMT5                   1001 non-null   int64\n",
      " 16  BILL_AMT6                   1001 non-null   int64\n",
      " 17  PAY_AMT1                    1001 non-null   int64\n",
      " 18  PAY_AMT2                    1001 non-null   int64\n",
      " 19  PAY_AMT3                    1001 non-null   int64\n",
      " 20  PAY_AMT4                    1001 non-null   int64\n",
      " 21  PAY_AMT5                    1001 non-null   int64\n",
      " 22  PAY_AMT6                    1001 non-null   int64\n",
      " 23  default payment next month  1001 non-null   int64\n",
      "dtypes: int64(24)\n",
      "memory usage: 187.8 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>167532.467532</td>\n",
       "      <td>1.589411</td>\n",
       "      <td>1.776224</td>\n",
       "      <td>1.604396</td>\n",
       "      <td>34.945055</td>\n",
       "      <td>-0.004995</td>\n",
       "      <td>-0.161838</td>\n",
       "      <td>-0.164835</td>\n",
       "      <td>-0.283716</td>\n",
       "      <td>-0.283716</td>\n",
       "      <td>...</td>\n",
       "      <td>40748.408591</td>\n",
       "      <td>39078.666334</td>\n",
       "      <td>38012.011988</td>\n",
       "      <td>5382.339660</td>\n",
       "      <td>5051.400599</td>\n",
       "      <td>4176.149850</td>\n",
       "      <td>4671.488511</td>\n",
       "      <td>5331.049950</td>\n",
       "      <td>5090.704296</td>\n",
       "      <td>0.213786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>130587.921320</td>\n",
       "      <td>0.492187</td>\n",
       "      <td>0.750916</td>\n",
       "      <td>0.532298</td>\n",
       "      <td>9.219760</td>\n",
       "      <td>1.173446</td>\n",
       "      <td>1.228732</td>\n",
       "      <td>1.262459</td>\n",
       "      <td>1.184662</td>\n",
       "      <td>1.170224</td>\n",
       "      <td>...</td>\n",
       "      <td>68206.929510</td>\n",
       "      <td>63108.238729</td>\n",
       "      <td>63074.415024</td>\n",
       "      <td>12180.755275</td>\n",
       "      <td>15626.153184</td>\n",
       "      <td>10514.647502</td>\n",
       "      <td>13269.943983</td>\n",
       "      <td>16812.536877</td>\n",
       "      <td>23658.888052</td>\n",
       "      <td>0.410183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3684.000000</td>\n",
       "      <td>-28335.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1423.000000</td>\n",
       "      <td>1206.000000</td>\n",
       "      <td>830.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>228.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17710.000000</td>\n",
       "      <td>17580.000000</td>\n",
       "      <td>15846.000000</td>\n",
       "      <td>2184.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>1206.000000</td>\n",
       "      <td>1398.000000</td>\n",
       "      <td>1306.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>48851.000000</td>\n",
       "      <td>46404.000000</td>\n",
       "      <td>46557.000000</td>\n",
       "      <td>5090.000000</td>\n",
       "      <td>4500.000000</td>\n",
       "      <td>3720.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>3745.000000</td>\n",
       "      <td>3784.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>700000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>628699.000000</td>\n",
       "      <td>484612.000000</td>\n",
       "      <td>473944.000000</td>\n",
       "      <td>199646.000000</td>\n",
       "      <td>285138.000000</td>\n",
       "      <td>133657.000000</td>\n",
       "      <td>188840.000000</td>\n",
       "      <td>195599.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LIMIT_BAL          SEX    EDUCATION     MARRIAGE          AGE  \\\n",
       "count    1001.000000  1001.000000  1001.000000  1001.000000  1001.000000   \n",
       "mean   167532.467532     1.589411     1.776224     1.604396    34.945055   \n",
       "std    130587.921320     0.492187     0.750916     0.532298     9.219760   \n",
       "min     10000.000000     1.000000     1.000000     0.000000    21.000000   \n",
       "25%     50000.000000     1.000000     1.000000     1.000000    28.000000   \n",
       "50%    140000.000000     2.000000     2.000000     2.000000    33.000000   \n",
       "75%    240000.000000     2.000000     2.000000     2.000000    41.000000   \n",
       "max    700000.000000     2.000000     6.000000     3.000000    75.000000   \n",
       "\n",
       "             PAY_0        PAY_2        PAY_3        PAY_4        PAY_5  ...  \\\n",
       "count  1001.000000  1001.000000  1001.000000  1001.000000  1001.000000  ...   \n",
       "mean     -0.004995    -0.161838    -0.164835    -0.283716    -0.283716  ...   \n",
       "std       1.173446     1.228732     1.262459     1.184662     1.170224  ...   \n",
       "min      -2.000000    -2.000000    -2.000000    -2.000000    -2.000000  ...   \n",
       "25%      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       8.000000     7.000000     7.000000     7.000000     7.000000  ...   \n",
       "\n",
       "           BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\n",
       "count    1001.000000    1001.000000    1001.000000    1001.000000   \n",
       "mean    40748.408591   39078.666334   38012.011988    5382.339660   \n",
       "std     68206.929510   63108.238729   63074.415024   12180.755275   \n",
       "min     -3684.000000  -28335.000000 -339603.000000       0.000000   \n",
       "25%      1423.000000    1206.000000     830.000000    1000.000000   \n",
       "50%     17710.000000   17580.000000   15846.000000    2184.000000   \n",
       "75%     48851.000000   46404.000000   46557.000000    5090.000000   \n",
       "max    628699.000000  484612.000000  473944.000000  199646.000000   \n",
       "\n",
       "            PAY_AMT2       PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
       "count    1001.000000    1001.000000    1001.000000    1001.000000   \n",
       "mean     5051.400599    4176.149850    4671.488511    5331.049950   \n",
       "std     15626.153184   10514.647502   13269.943983   16812.536877   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%       390.000000     228.000000     148.000000     189.000000   \n",
       "50%      1710.000000    1206.000000    1398.000000    1306.000000   \n",
       "75%      4500.000000    3720.000000    4000.000000    3745.000000   \n",
       "max    285138.000000  133657.000000  188840.000000  195599.000000   \n",
       "\n",
       "            PAY_AMT6  default payment next month  \n",
       "count    1001.000000                 1001.000000  \n",
       "mean     5090.704296                    0.213786  \n",
       "std     23658.888052                    0.410183  \n",
       "min         0.000000                    0.000000  \n",
       "25%         0.000000                    0.000000  \n",
       "50%      1250.000000                    0.000000  \n",
       "75%      3784.000000                    0.000000  \n",
       "max    528666.000000                    1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile=ProfileReport(df=data,title=\"Pandas Profiling report\")\n",
    "# profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.drop(\"default payment next month\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35835</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57608</td>\n",
       "      <td>19394</td>\n",
       "      <td>19619</td>\n",
       "      <td>20024</td>\n",
       "      <td>2500</td>\n",
       "      <td>1815</td>\n",
       "      <td>657</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>445007</td>\n",
       "      <td>542653</td>\n",
       "      <td>483003</td>\n",
       "      <td>473944</td>\n",
       "      <td>55000</td>\n",
       "      <td>40000</td>\n",
       "      <td>38000</td>\n",
       "      <td>20239</td>\n",
       "      <td>13750</td>\n",
       "      <td>13770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>601</td>\n",
       "      <td>221</td>\n",
       "      <td>-159</td>\n",
       "      <td>567</td>\n",
       "      <td>380</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>1687</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12108</td>\n",
       "      <td>12211</td>\n",
       "      <td>11793</td>\n",
       "      <td>3719</td>\n",
       "      <td>3329</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      50000    1          2         1   57     -1      0     -1      0   \n",
       "1      50000    1          1         2   37      0      0      0      0   \n",
       "2     500000    1          1         2   29      0      0      0      0   \n",
       "3     100000    2          2         2   23      0     -1     -1      0   \n",
       "4     140000    2          3         1   28      0      0      2      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT3  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0      0  ...      35835      20940      19146      19131      2000     36681   \n",
       "1      0  ...      57608      19394      19619      20024      2500      1815   \n",
       "2      0  ...     445007     542653     483003     473944     55000     40000   \n",
       "3      0  ...        601        221       -159        567       380       601   \n",
       "4      0  ...      12108      12211      11793       3719      3329         0   \n",
       "\n",
       "   PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "0     10000      9000       689       679  \n",
       "1       657      1000      1000       800  \n",
       "2     38000     20239     13750     13770  \n",
       "3         0       581      1687      1542  \n",
       "4       432      1000      1000      1000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default payment next month\n",
       "0    787\n",
       "1    214\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['default payment next month'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class=data[data['default payment next month']==0]\n",
    "minority_class=data[data['default payment next month']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority_class_resampled=resample(minority_class,replace=True,n_samples=len(majority_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(787, 24)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_class_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_resampled=pd.concat([majority_class,minority_class_resampled],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19394</td>\n",
       "      <td>19619</td>\n",
       "      <td>20024</td>\n",
       "      <td>2500</td>\n",
       "      <td>1815</td>\n",
       "      <td>657</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>542653</td>\n",
       "      <td>483003</td>\n",
       "      <td>473944</td>\n",
       "      <td>55000</td>\n",
       "      <td>40000</td>\n",
       "      <td>38000</td>\n",
       "      <td>20239</td>\n",
       "      <td>13750</td>\n",
       "      <td>13770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>-159</td>\n",
       "      <td>567</td>\n",
       "      <td>380</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>1687</td>\n",
       "      <td>1542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12211</td>\n",
       "      <td>11793</td>\n",
       "      <td>3719</td>\n",
       "      <td>3329</td>\n",
       "      <td>0</td>\n",
       "      <td>432</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>270000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>217644</td>\n",
       "      <td>223690</td>\n",
       "      <td>221413</td>\n",
       "      <td>10000</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>16000</td>\n",
       "      <td>8000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12841</td>\n",
       "      <td>13836</td>\n",
       "      <td>14514</td>\n",
       "      <td>1200</td>\n",
       "      <td>1200</td>\n",
       "      <td>2000</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5347</td>\n",
       "      <td>6375</td>\n",
       "      <td>7077</td>\n",
       "      <td>1000</td>\n",
       "      <td>1066</td>\n",
       "      <td>1300</td>\n",
       "      <td>1500</td>\n",
       "      <td>1200</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>360000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>1170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>290000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>284660</td>\n",
       "      <td>255892</td>\n",
       "      <td>238266</td>\n",
       "      <td>13000</td>\n",
       "      <td>10200</td>\n",
       "      <td>10265</td>\n",
       "      <td>8803</td>\n",
       "      <td>8300</td>\n",
       "      <td>8546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1574 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0         50000    1          2         1   57     -1      0     -1      0   \n",
       "1         50000    1          1         2   37      0      0      0      0   \n",
       "2        500000    1          1         2   29      0      0      0      0   \n",
       "3        100000    2          2         2   23      0     -1     -1      0   \n",
       "4        140000    2          3         1   28      0      0      2      0   \n",
       "...         ...  ...        ...       ...  ...    ...    ...    ...    ...   \n",
       "1569     270000    2          2         1   32      1      2      2      2   \n",
       "1570      30000    1          3         1   55      2      2      2      3   \n",
       "1571      50000    1          2         1   51      0      0      0      0   \n",
       "1572     360000    2          1         1   45     -1     -1      2      0   \n",
       "1573     290000    1          1         1   53      2      0      0      0   \n",
       "\n",
       "      PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0         0  ...      20940      19146      19131      2000     36681   \n",
       "1         0  ...      19394      19619      20024      2500      1815   \n",
       "2         0  ...     542653     483003     473944     55000     40000   \n",
       "3         0  ...        221       -159        567       380       601   \n",
       "4         0  ...      12211      11793       3719      3329         0   \n",
       "...     ...  ...        ...        ...        ...       ...       ...   \n",
       "1569      2  ...     217644     223690     221413     10000      8000   \n",
       "1570      3  ...      12841      13836      14514      1200      1200   \n",
       "1571      0  ...       5347       6375       7077      1000      1066   \n",
       "1572     -1  ...        390        390        390      1170         0   \n",
       "1573      0  ...     284660     255892     238266     13000     10200   \n",
       "\n",
       "      PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0        10000      9000       689       679                           0  \n",
       "1          657      1000      1000       800                           0  \n",
       "2        38000     20239     13750     13770                           0  \n",
       "3            0       581      1687      1542                           0  \n",
       "4          432      1000      1000      1000                           0  \n",
       "...        ...       ...       ...       ...                         ...  \n",
       "1569         0     16000      8000         0                           1  \n",
       "1570      2000      1500      1500      1500                           1  \n",
       "1571      1300      1500      1200       134                           1  \n",
       "1572         0       390       390       390                           1  \n",
       "1573     10265      8803      8300      8546                           1  \n",
       "\n",
       "[1574 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data_resampled.drop(\"default payment next month\",axis=1)\n",
    "y=data_resampled['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in data_resampled.columns:\n",
    "#     print(data_resampled[col].nunique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled=scaler.fit_transform(x_train)\n",
    "x_test_scaled=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66       198\n",
      "           1       0.65      0.57      0.61       196\n",
      "\n",
      "    accuracy                           0.63       394\n",
      "   macro avg       0.64      0.63      0.63       394\n",
      "weighted avg       0.64      0.63      0.63       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,model_0.predict(x_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    \"penalty\":['l1','l2','elasticnet',None],\n",
    "    \"C\":[1,10,20,30,40,50],\n",
    "    \"solver\":[\"lbfgs\",\"liblinear\",\"newton-cg\",\"newton-cholesky\",\"sag\",\"saga\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(estimator=LogisticRegression(),param_grid=params,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1192: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "330 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1178, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Programs\\Python\\PW\\projects\\credit_card_fault_detection\\env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.66864407        nan        nan        nan 0.63474576\n",
      " 0.66694915 0.66694915 0.66694915 0.66694915 0.65847458 0.63135593\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66440678        nan 0.66525424 0.66525424 0.65932203 0.63220339\n",
      "        nan 0.66525424        nan        nan        nan 0.63135593\n",
      " 0.66525424 0.66525424 0.66525424 0.66525424 0.65847458 0.63135593\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66440678        nan 0.66525424 0.66525424 0.65847458 0.63220339\n",
      "        nan 0.66525424        nan        nan        nan 0.63220339\n",
      " 0.66525424 0.66525424 0.66525424 0.66525424 0.65932203 0.63050847\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66440678        nan 0.66525424 0.66525424 0.65932203 0.63220339\n",
      "        nan 0.66525424        nan        nan        nan 0.63220339\n",
      " 0.66525424 0.66525424 0.66525424 0.66525424 0.65847458 0.62966102\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66440678        nan 0.66525424 0.66525424 0.65932203 0.63135593\n",
      "        nan 0.66525424        nan        nan        nan 0.63305085\n",
      " 0.66525424 0.66525424 0.66525424 0.66525424 0.65932203 0.63135593\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66440678        nan 0.66525424 0.66525424 0.65932203 0.63220339\n",
      "        nan 0.66525424        nan        nan        nan 0.63305085\n",
      " 0.66525424 0.66525424 0.66525424 0.66525424 0.65847458 0.63050847\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66440678        nan 0.66525424 0.66525424 0.65932203 0.63220339]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 20, 30, 40, 50],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 10, 20, 30, 40, 50],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1, 10, 20, 30, 40, 50],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
       "                                    'newton-cholesky', 'sag', 'saga']})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67       198\n",
      "           1       0.66      0.66      0.66       196\n",
      "\n",
      "    accuracy                           0.66       394\n",
      "   macro avg       0.66      0.66      0.66       394\n",
      "weighted avg       0.66      0.66      0.66       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,model_1.predict(x_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    \"criterion\":[\"gini\",\"entropy\",\"log_loss\"],\n",
    "    \"splitter\":['best','random'],\n",
    "    \"max_depth\":[15,16,17,18,20,21,22,23,24,25,26],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(estimator=DecisionTreeClassifier(),param_grid=params,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [15, 16, 17, 18, 20, 21, 22, 23, 24, 25,\n",
       "                                       26],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [15, 16, 17, 18, 20, 21, 22, 23, 24, 25,\n",
       "                                       26],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [15, 16, 17, 18, 20, 21, 22, 23, 24, 25,\n",
       "                                       26],\n",
       "                         'splitter': ['best', 'random']})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2=grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=23, splitter=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=23, splitter=&#x27;random&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=23, splitter='random')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=23, splitter=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=23, splitter=&#x27;random&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=23, splitter='random')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80       198\n",
      "           1       0.78      0.87      0.82       196\n",
      "\n",
      "    accuracy                           0.81       394\n",
      "   macro avg       0.81      0.81      0.81       394\n",
      "weighted avg       0.81      0.81      0.81       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,model_2.predict(x_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74       198\n",
      "           1       0.74      0.76      0.75       196\n",
      "\n",
      "    accuracy                           0.75       394\n",
      "   macro avg       0.75      0.75      0.75       394\n",
      "weighted avg       0.75      0.75      0.75       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,model_3.predict(x_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91       198\n",
      "           1       0.88      0.97      0.92       196\n",
      "\n",
      "    accuracy                           0.92       394\n",
      "   macro avg       0.92      0.92      0.92       394\n",
      "weighted avg       0.92      0.92      0.92       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,model_4.predict(x_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5=AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       198\n",
      "           1       0.71      0.75      0.73       196\n",
      "\n",
      "    accuracy                           0.73       394\n",
      "   macro avg       0.73      0.73      0.73       394\n",
      "weighted avg       0.73      0.73      0.73       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,model_5.predict(x_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82       198\n",
      "           1       0.81      0.87      0.84       196\n",
      "\n",
      "    accuracy                           0.83       394\n",
      "   macro avg       0.83      0.83      0.83       394\n",
      "weighted avg       0.83      0.83      0.83       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,model_6.predict(x_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=[\n",
    "    keras.layers.Input(shape=x_train_scaled.shape[1:]),\n",
    "    Dense(10,activation='relu'),\n",
    "    Dense(5,activation='relu'),\n",
    "    Dense(2,activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7=Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                240       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307 (1.20 KB)\n",
      "Trainable params: 307 (1.20 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "118/118 - 0s - loss: 0.5428 - accuracy: 0.7458 - 315ms/epoch - 3ms/step\n",
      "Epoch 2/50\n",
      "118/118 - 0s - loss: 0.5382 - accuracy: 0.7424 - 289ms/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "118/118 - 0s - loss: 0.5329 - accuracy: 0.7449 - 290ms/epoch - 2ms/step\n",
      "Epoch 4/50\n",
      "118/118 - 0s - loss: 0.5287 - accuracy: 0.7517 - 295ms/epoch - 2ms/step\n",
      "Epoch 5/50\n",
      "118/118 - 0s - loss: 0.5262 - accuracy: 0.7525 - 194ms/epoch - 2ms/step\n",
      "Epoch 6/50\n",
      "118/118 - 0s - loss: 0.5206 - accuracy: 0.7551 - 190ms/epoch - 2ms/step\n",
      "Epoch 7/50\n",
      "118/118 - 0s - loss: 0.5180 - accuracy: 0.7525 - 184ms/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "118/118 - 0s - loss: 0.5122 - accuracy: 0.7686 - 185ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "118/118 - 0s - loss: 0.5102 - accuracy: 0.7585 - 184ms/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "118/118 - 0s - loss: 0.5060 - accuracy: 0.7644 - 208ms/epoch - 2ms/step\n",
      "Epoch 11/50\n",
      "118/118 - 0s - loss: 0.5029 - accuracy: 0.7695 - 208ms/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "118/118 - 0s - loss: 0.4993 - accuracy: 0.7636 - 200ms/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "118/118 - 0s - loss: 0.4964 - accuracy: 0.7695 - 193ms/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "118/118 - 0s - loss: 0.4948 - accuracy: 0.7653 - 201ms/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "118/118 - 0s - loss: 0.4904 - accuracy: 0.7686 - 185ms/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "118/118 - 0s - loss: 0.4860 - accuracy: 0.7729 - 183ms/epoch - 2ms/step\n",
      "Epoch 17/50\n",
      "118/118 - 0s - loss: 0.4841 - accuracy: 0.7712 - 183ms/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "118/118 - 0s - loss: 0.4798 - accuracy: 0.7763 - 185ms/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "118/118 - 0s - loss: 0.4774 - accuracy: 0.7805 - 267ms/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "118/118 - 0s - loss: 0.4766 - accuracy: 0.7907 - 200ms/epoch - 2ms/step\n",
      "Epoch 21/50\n",
      "118/118 - 0s - loss: 0.4722 - accuracy: 0.7839 - 200ms/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "118/118 - 0s - loss: 0.4723 - accuracy: 0.7881 - 225ms/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "118/118 - 0s - loss: 0.4685 - accuracy: 0.7898 - 217ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "118/118 - 0s - loss: 0.4670 - accuracy: 0.7924 - 208ms/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "118/118 - 0s - loss: 0.4630 - accuracy: 0.7907 - 192ms/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "118/118 - 0s - loss: 0.4614 - accuracy: 0.7881 - 201ms/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "118/118 - 0s - loss: 0.4586 - accuracy: 0.7881 - 185ms/epoch - 2ms/step\n",
      "Epoch 28/50\n",
      "118/118 - 0s - loss: 0.4584 - accuracy: 0.7907 - 194ms/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "118/118 - 0s - loss: 0.4548 - accuracy: 0.7983 - 186ms/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "118/118 - 0s - loss: 0.4528 - accuracy: 0.7975 - 186ms/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "118/118 - 0s - loss: 0.4505 - accuracy: 0.8034 - 195ms/epoch - 2ms/step\n",
      "Epoch 32/50\n",
      "118/118 - 0s - loss: 0.4483 - accuracy: 0.7890 - 191ms/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "118/118 - 0s - loss: 0.4477 - accuracy: 0.8000 - 201ms/epoch - 2ms/step\n",
      "Epoch 34/50\n",
      "118/118 - 0s - loss: 0.4448 - accuracy: 0.8051 - 201ms/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "118/118 - 0s - loss: 0.4442 - accuracy: 0.7992 - 193ms/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "118/118 - 0s - loss: 0.4416 - accuracy: 0.8017 - 192ms/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "118/118 - 0s - loss: 0.4371 - accuracy: 0.8000 - 200ms/epoch - 2ms/step\n",
      "Epoch 38/50\n",
      "118/118 - 0s - loss: 0.4366 - accuracy: 0.8017 - 193ms/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "118/118 - 0s - loss: 0.4327 - accuracy: 0.7992 - 185ms/epoch - 2ms/step\n",
      "Epoch 40/50\n",
      "118/118 - 0s - loss: 0.4301 - accuracy: 0.8059 - 185ms/epoch - 2ms/step\n",
      "Epoch 41/50\n",
      "118/118 - 0s - loss: 0.4316 - accuracy: 0.8042 - 201ms/epoch - 2ms/step\n",
      "Epoch 42/50\n",
      "118/118 - 0s - loss: 0.4287 - accuracy: 0.8085 - 177ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "118/118 - 0s - loss: 0.4244 - accuracy: 0.8119 - 196ms/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "118/118 - 0s - loss: 0.4231 - accuracy: 0.8085 - 201ms/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "118/118 - 0s - loss: 0.4201 - accuracy: 0.8051 - 192ms/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "118/118 - 0s - loss: 0.4189 - accuracy: 0.8059 - 194ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "118/118 - 0s - loss: 0.4196 - accuracy: 0.8119 - 185ms/epoch - 2ms/step\n",
      "Epoch 48/50\n",
      "118/118 - 0s - loss: 0.4181 - accuracy: 0.8093 - 195ms/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "118/118 - 0s - loss: 0.4123 - accuracy: 0.8110 - 186ms/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "118/118 - 0s - loss: 0.4135 - accuracy: 0.8119 - 184ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "history=model_7.fit(x_train_scaled,y_train,batch_size=10,verbose=2,epochs=260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_1=[\n",
    "    keras.layers.Input(shape=x_train_scaled.shape[1:]),\n",
    "    Dense(50,activation='relu'),\n",
    "    Dense(30,activation='relu'),\n",
    "    Dense(10,activation='relu'),\n",
    "    Dense(2,activation='softmax')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8=Sequential(layers_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 50)                1200      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 30)                1530      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3062 (11.96 KB)\n",
      "Trainable params: 3062 (11.96 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_8.compile(optimizer='Adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 - 1s - loss: 0.6770 - accuracy: 0.6068 - 1s/epoch - 12ms/step\n",
      "Epoch 2/100\n",
      "118/118 - 0s - loss: 0.5715 - accuracy: 0.7161 - 305ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "118/118 - 0s - loss: 0.5306 - accuracy: 0.7381 - 305ms/epoch - 3ms/step\n",
      "Epoch 4/100\n",
      "118/118 - 0s - loss: 0.5097 - accuracy: 0.7525 - 208ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "118/118 - 0s - loss: 0.5028 - accuracy: 0.7610 - 208ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "118/118 - 0s - loss: 0.4728 - accuracy: 0.7729 - 224ms/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "118/118 - 0s - loss: 0.4489 - accuracy: 0.7881 - 224ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "118/118 - 0s - loss: 0.4274 - accuracy: 0.8008 - 192ms/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "118/118 - 0s - loss: 0.4224 - accuracy: 0.8068 - 217ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "118/118 - 0s - loss: 0.3885 - accuracy: 0.8297 - 208ms/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "118/118 - 0s - loss: 0.3744 - accuracy: 0.8381 - 192ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "118/118 - 0s - loss: 0.3758 - accuracy: 0.8415 - 201ms/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "118/118 - 0s - loss: 0.3797 - accuracy: 0.8475 - 193ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "118/118 - 0s - loss: 0.3624 - accuracy: 0.8500 - 193ms/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "118/118 - 0s - loss: 0.3363 - accuracy: 0.8559 - 197ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "118/118 - 0s - loss: 0.3222 - accuracy: 0.8669 - 225ms/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "118/118 - 0s - loss: 0.2945 - accuracy: 0.8822 - 224ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "118/118 - 0s - loss: 0.2916 - accuracy: 0.8856 - 225ms/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "118/118 - 0s - loss: 0.2758 - accuracy: 0.8949 - 216ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "118/118 - 0s - loss: 0.2793 - accuracy: 0.8932 - 217ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "118/118 - 0s - loss: 0.3176 - accuracy: 0.8847 - 208ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "118/118 - 0s - loss: 0.2525 - accuracy: 0.9102 - 177ms/epoch - 1ms/step\n",
      "Epoch 23/100\n",
      "118/118 - 0s - loss: 0.2369 - accuracy: 0.9161 - 193ms/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "118/118 - 0s - loss: 0.2250 - accuracy: 0.9136 - 185ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "118/118 - 0s - loss: 0.2145 - accuracy: 0.9254 - 202ms/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "118/118 - 0s - loss: 0.2256 - accuracy: 0.9127 - 201ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "118/118 - 0s - loss: 0.2325 - accuracy: 0.9076 - 192ms/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "118/118 - 0s - loss: 0.2150 - accuracy: 0.9280 - 192ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "118/118 - 0s - loss: 0.1901 - accuracy: 0.9339 - 195ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "118/118 - 0s - loss: 0.1860 - accuracy: 0.9280 - 184ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "118/118 - 0s - loss: 0.1707 - accuracy: 0.9415 - 185ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "118/118 - 0s - loss: 0.1615 - accuracy: 0.9483 - 192ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "118/118 - 0s - loss: 0.1581 - accuracy: 0.9466 - 193ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "118/118 - 0s - loss: 0.1472 - accuracy: 0.9525 - 190ms/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "118/118 - 0s - loss: 0.1488 - accuracy: 0.9492 - 191ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "118/118 - 0s - loss: 0.1464 - accuracy: 0.9610 - 193ms/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "118/118 - 0s - loss: 0.1781 - accuracy: 0.9339 - 232ms/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "118/118 - 0s - loss: 0.1378 - accuracy: 0.9593 - 184ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "118/118 - 0s - loss: 0.1735 - accuracy: 0.9492 - 208ms/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "118/118 - 0s - loss: 0.1346 - accuracy: 0.9576 - 192ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "118/118 - 0s - loss: 0.1089 - accuracy: 0.9712 - 193ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "118/118 - 0s - loss: 0.1062 - accuracy: 0.9686 - 193ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "118/118 - 0s - loss: 0.1033 - accuracy: 0.9703 - 193ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "118/118 - 0s - loss: 0.0943 - accuracy: 0.9729 - 193ms/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "118/118 - 0s - loss: 0.0908 - accuracy: 0.9763 - 201ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "118/118 - 0s - loss: 0.1010 - accuracy: 0.9720 - 183ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "118/118 - 0s - loss: 0.0940 - accuracy: 0.9737 - 204ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "118/118 - 0s - loss: 0.0810 - accuracy: 0.9763 - 193ms/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "118/118 - 0s - loss: 0.0840 - accuracy: 0.9788 - 201ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "118/118 - 0s - loss: 0.0933 - accuracy: 0.9729 - 194ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "118/118 - 0s - loss: 0.0773 - accuracy: 0.9805 - 185ms/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "118/118 - 0s - loss: 0.0723 - accuracy: 0.9839 - 193ms/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "118/118 - 0s - loss: 0.1070 - accuracy: 0.9661 - 200ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "118/118 - 0s - loss: 0.1041 - accuracy: 0.9661 - 187ms/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "118/118 - 0s - loss: 0.0694 - accuracy: 0.9822 - 188ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "118/118 - 0s - loss: 0.0738 - accuracy: 0.9720 - 184ms/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "118/118 - 0s - loss: 0.1167 - accuracy: 0.9644 - 209ms/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "118/118 - 0s - loss: 0.1465 - accuracy: 0.9610 - 200ms/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "118/118 - 0s - loss: 0.0908 - accuracy: 0.9780 - 184ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "118/118 - 0s - loss: 0.0584 - accuracy: 0.9839 - 200ms/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "118/118 - 0s - loss: 0.0516 - accuracy: 0.9890 - 184ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "118/118 - 0s - loss: 0.0540 - accuracy: 0.9847 - 209ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "118/118 - 0s - loss: 0.0524 - accuracy: 0.9873 - 185ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "118/118 - 0s - loss: 0.0472 - accuracy: 0.9873 - 202ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "118/118 - 0s - loss: 0.0511 - accuracy: 0.9890 - 195ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "118/118 - 0s - loss: 0.0515 - accuracy: 0.9839 - 193ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "118/118 - 0s - loss: 0.0531 - accuracy: 0.9839 - 199ms/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "118/118 - 0s - loss: 0.0503 - accuracy: 0.9847 - 192ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "118/118 - 0s - loss: 0.0416 - accuracy: 0.9890 - 192ms/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "118/118 - 0s - loss: 0.0543 - accuracy: 0.9847 - 200ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "118/118 - 0s - loss: 0.0450 - accuracy: 0.9890 - 202ms/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "118/118 - 0s - loss: 0.0479 - accuracy: 0.9839 - 185ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "118/118 - 0s - loss: 0.0313 - accuracy: 0.9941 - 185ms/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "118/118 - 0s - loss: 0.0387 - accuracy: 0.9907 - 193ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "118/118 - 0s - loss: 0.0878 - accuracy: 0.9763 - 199ms/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "118/118 - 0s - loss: 0.1183 - accuracy: 0.9712 - 200ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "118/118 - 0s - loss: 0.0763 - accuracy: 0.9788 - 201ms/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "118/118 - 0s - loss: 0.0473 - accuracy: 0.9898 - 193ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "118/118 - 0s - loss: 0.0350 - accuracy: 0.9898 - 185ms/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "118/118 - 0s - loss: 0.0289 - accuracy: 0.9924 - 193ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "118/118 - 0s - loss: 0.0437 - accuracy: 0.9881 - 193ms/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "118/118 - 0s - loss: 0.0422 - accuracy: 0.9856 - 194ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "118/118 - 0s - loss: 0.0284 - accuracy: 0.9932 - 190ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "118/118 - 0s - loss: 0.0252 - accuracy: 0.9932 - 195ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "118/118 - 0s - loss: 0.0286 - accuracy: 0.9915 - 200ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "118/118 - 0s - loss: 0.0211 - accuracy: 0.9958 - 190ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "118/118 - 0s - loss: 0.0211 - accuracy: 0.9958 - 193ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "118/118 - 0s - loss: 0.0242 - accuracy: 0.9958 - 184ms/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "118/118 - 0s - loss: 0.0209 - accuracy: 0.9949 - 186ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "118/118 - 0s - loss: 0.0345 - accuracy: 0.9907 - 208ms/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "118/118 - 0s - loss: 0.0354 - accuracy: 0.9873 - 187ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "118/118 - 0s - loss: 0.0233 - accuracy: 0.9924 - 191ms/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "118/118 - 0s - loss: 0.0405 - accuracy: 0.9873 - 200ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "118/118 - 0s - loss: 0.0205 - accuracy: 0.9941 - 192ms/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "118/118 - 0s - loss: 0.0179 - accuracy: 0.9958 - 200ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "118/118 - 0s - loss: 0.0827 - accuracy: 0.9771 - 192ms/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "118/118 - 0s - loss: 0.0441 - accuracy: 0.9839 - 200ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "118/118 - 0s - loss: 0.0242 - accuracy: 0.9941 - 193ms/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "118/118 - 0s - loss: 0.0379 - accuracy: 0.9873 - 186ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "118/118 - 0s - loss: 0.0218 - accuracy: 0.9949 - 202ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19fbf3ea4a0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_8.fit(x_train_scaled,y_train,batch_size=10,verbose=2,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- so this model is performing far better than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model_8.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.87520456e-01 2.41445918e-02]\n",
      " [9.93125677e-01 1.78485028e-02]\n",
      " [9.99379337e-01 4.73759649e-03]\n",
      " [9.98991013e-01 6.84609986e-04]\n",
      " [1.23932827e-02 2.48737514e-01]\n",
      " [1.79389536e-01 6.62545741e-01]\n",
      " [1.08766789e-02 9.90192711e-01]\n",
      " [9.74866211e-01 9.59644094e-03]\n",
      " [1.55165361e-03 3.82525563e-01]\n",
      " [9.91842151e-01 3.92450951e-02]\n",
      " [7.22166896e-03 9.86373186e-01]\n",
      " [1.63177128e-06 9.49529111e-01]\n",
      " [1.63177128e-06 9.49529111e-01]\n",
      " [6.70404464e-04 2.54559547e-01]\n",
      " [4.62413562e-04 9.75672007e-01]\n",
      " [1.00000000e+00 4.75401833e-08]\n",
      " [2.47675050e-02 9.79691505e-01]\n",
      " [9.99999583e-01 3.03902493e-06]\n",
      " [7.72372494e-03 9.77632582e-01]\n",
      " [8.17684770e-01 5.27212098e-02]\n",
      " [1.79389536e-01 6.62545741e-01]\n",
      " [4.36815888e-01 4.03398812e-01]\n",
      " [9.60701883e-01 6.49207607e-02]\n",
      " [1.44038734e-03 9.85799074e-01]\n",
      " [7.40258911e-05 9.93888497e-01]\n",
      " [9.99999285e-01 3.86273496e-06]\n",
      " [6.21529043e-01 6.03921354e-01]\n",
      " [3.49100120e-02 6.19284987e-01]\n",
      " [9.99809027e-01 6.37339428e-04]\n",
      " [9.99574125e-01 8.27038474e-03]\n",
      " [4.63433703e-03 5.76994717e-01]\n",
      " [9.90933776e-01 6.42434554e-03]\n",
      " [2.60773941e-05 9.89177406e-01]\n",
      " [2.80086428e-01 8.09503734e-01]\n",
      " [7.42099015e-04 6.81683958e-01]\n",
      " [9.77016151e-01 2.49290317e-02]\n",
      " [9.33937550e-01 7.45132342e-02]\n",
      " [6.06041551e-01 4.59776044e-01]\n",
      " [9.99905825e-01 9.10396129e-02]\n",
      " [1.91568478e-03 8.01427841e-01]\n",
      " [1.00000000e+00 0.00000000e+00]\n",
      " [9.99997199e-01 3.80401500e-04]\n",
      " [4.36815888e-01 4.03398812e-01]\n",
      " [7.09104817e-03 8.88678432e-01]\n",
      " [1.00000000e+00 4.69940276e-12]\n",
      " [9.99994099e-01 5.50867553e-05]\n",
      " [1.64551046e-02 6.56395972e-01]\n",
      " [9.99460518e-01 7.69103121e-04]\n",
      " [9.88004029e-01 1.86493862e-02]\n",
      " [9.99999702e-01 2.74286435e-07]\n",
      " [2.10546097e-03 3.70538056e-01]\n",
      " [9.97811794e-01 6.11004746e-03]\n",
      " [1.62495789e-03 9.53449011e-01]\n",
      " [4.36815888e-01 4.03398812e-01]\n",
      " [1.12233707e-03 9.83263254e-01]\n",
      " [9.55018938e-01 4.95985895e-02]\n",
      " [5.87710030e-02 6.52517438e-01]\n",
      " [2.52130926e-01 2.50662655e-01]\n",
      " [9.83144820e-01 1.72902737e-02]\n",
      " [2.07221676e-02 5.96376181e-01]\n",
      " [1.00000000e+00 2.48715653e-12]\n",
      " [8.72727670e-03 7.23871946e-01]\n",
      " [6.39509380e-01 2.28290394e-01]\n",
      " [3.67348939e-01 5.44242084e-01]\n",
      " [9.98793304e-01 7.10866554e-03]\n",
      " [8.47082219e-07 9.99729872e-01]\n",
      " [6.63867518e-02 8.62319410e-01]\n",
      " [9.99872923e-01 2.76115781e-04]\n",
      " [1.51270917e-02 7.22433805e-01]\n",
      " [1.60658988e-03 9.30721283e-01]\n",
      " [9.97044444e-01 4.14661597e-03]\n",
      " [1.00000000e+00 9.34000298e-07]\n",
      " [8.53635211e-05 5.88857472e-01]\n",
      " [1.91010985e-09 9.98954535e-01]\n",
      " [1.51313073e-03 5.60869753e-01]\n",
      " [1.47356018e-01 6.29940927e-01]\n",
      " [9.99675810e-01 6.92867499e-04]\n",
      " [1.63177128e-06 9.49529111e-01]\n",
      " [4.23529884e-03 8.95718932e-01]\n",
      " [9.44134891e-01 5.65044470e-02]\n",
      " [9.99016106e-01 9.75682691e-04]\n",
      " [7.87278175e-01 2.68258452e-01]\n",
      " [9.99997318e-01 8.23961454e-06]\n",
      " [9.98282731e-01 6.26727007e-04]\n",
      " [9.79147494e-01 2.80647725e-02]\n",
      " [1.78115920e-03 1.07418345e-02]\n",
      " [2.80086428e-01 8.09503734e-01]\n",
      " [9.99544501e-01 3.58763314e-03]\n",
      " [1.03253944e-06 9.94465053e-01]\n",
      " [1.00000000e+00 2.07020190e-37]\n",
      " [3.82012135e-04 8.92377853e-01]\n",
      " [3.04057479e-01 5.37442625e-01]\n",
      " [7.98242927e-01 2.58071333e-01]\n",
      " [5.67173702e-05 6.92673028e-01]\n",
      " [9.97930288e-01 9.67728323e-04]\n",
      " [1.91572108e-04 5.08885026e-01]\n",
      " [8.17926288e-01 1.18300721e-01]\n",
      " [9.94372487e-01 8.95154104e-03]\n",
      " [9.43855882e-01 8.11169073e-02]\n",
      " [5.31234138e-04 7.15308785e-01]\n",
      " [2.07070503e-02 6.28087223e-01]\n",
      " [9.83817637e-01 2.09062826e-02]\n",
      " [9.99999881e-01 5.94737571e-07]\n",
      " [9.66576219e-01 1.40877413e-02]\n",
      " [5.10214791e-02 8.17808807e-01]\n",
      " [7.96222806e-01 2.77082771e-01]\n",
      " [9.73661959e-01 2.51096245e-02]\n",
      " [1.04035498e-04 9.96728957e-01]\n",
      " [9.63238720e-03 6.90214336e-01]\n",
      " [6.61187759e-03 9.77784634e-01]\n",
      " [6.30328759e-06 9.95818973e-01]\n",
      " [2.18504891e-01 8.82167399e-01]\n",
      " [7.23567791e-03 4.02333498e-01]\n",
      " [9.23046410e-01 1.14463881e-01]\n",
      " [9.74866211e-01 9.59644094e-03]\n",
      " [7.09104817e-03 8.88678432e-01]\n",
      " [9.96851325e-01 1.20475180e-02]\n",
      " [1.13122487e-05 3.00681358e-03]\n",
      " [9.99694943e-01 4.18624748e-03]\n",
      " [9.91888344e-01 3.03387176e-02]\n",
      " [1.32400990e-02 4.35210347e-01]\n",
      " [1.00000000e+00 3.13289607e-12]\n",
      " [8.30417052e-02 2.25720996e-05]\n",
      " [5.78240352e-03 7.41976738e-01]\n",
      " [9.19926345e-01 6.04461990e-02]\n",
      " [9.98629034e-01 7.71651464e-03]\n",
      " [1.55165652e-03 3.82525295e-01]\n",
      " [1.20068239e-02 9.15655136e-01]\n",
      " [1.31833006e-03 9.36391115e-01]\n",
      " [3.53695522e-03 9.50806141e-01]\n",
      " [9.99983311e-01 5.50480263e-06]\n",
      " [9.92682278e-01 2.63444185e-02]\n",
      " [5.97512536e-03 8.62211406e-01]\n",
      " [5.07990569e-02 5.28739631e-01]\n",
      " [9.99993384e-01 8.69907217e-06]\n",
      " [7.09104817e-03 8.88678432e-01]\n",
      " [9.99781787e-01 4.49586019e-04]\n",
      " [4.61641639e-01 3.54820728e-01]\n",
      " [3.58357723e-03 9.89668727e-01]\n",
      " [8.11465502e-01 1.58267155e-01]\n",
      " [9.93806064e-01 1.36822369e-02]\n",
      " [7.68204033e-03 6.95336998e-01]\n",
      " [9.99982357e-01 2.24793442e-02]\n",
      " [9.36494589e-01 2.37990916e-01]\n",
      " [2.36409786e-03 7.75151610e-01]\n",
      " [1.31833006e-03 9.36391115e-01]\n",
      " [4.99358267e-01 1.03321113e-01]\n",
      " [3.74493119e-03 9.96590614e-01]\n",
      " [1.60658988e-03 9.30721283e-01]\n",
      " [9.62349959e-03 4.75417614e-01]\n",
      " [3.75084416e-03 5.21185696e-01]\n",
      " [1.63177128e-06 9.49529111e-01]\n",
      " [3.17091942e-02 9.17544723e-01]\n",
      " [1.64551046e-02 6.56395972e-01]\n",
      " [7.24918127e-01 1.04345433e-01]\n",
      " [9.99867320e-01 2.44852575e-03]\n",
      " [8.72727670e-03 7.23871946e-01]\n",
      " [9.95303273e-01 4.26156353e-03]\n",
      " [1.00000000e+00 7.80921910e-05]\n",
      " [9.95742321e-01 4.76693735e-03]\n",
      " [9.98531759e-01 1.04986336e-02]\n",
      " [1.08766789e-02 9.90192711e-01]\n",
      " [9.87797081e-01 2.64507160e-02]\n",
      " [9.99957681e-01 3.69217945e-03]\n",
      " [4.62413562e-04 9.75672007e-01]\n",
      " [9.99906600e-01 1.66166842e-03]\n",
      " [6.69298810e-04 6.62901044e-01]\n",
      " [2.31765881e-02 9.46770906e-01]\n",
      " [1.72462203e-02 9.47891772e-01]\n",
      " [9.88278568e-01 4.92190616e-03]\n",
      " [3.74493119e-03 9.96590614e-01]\n",
      " [9.19839323e-01 1.55889958e-01]\n",
      " [8.88493285e-03 6.99852824e-01]\n",
      " [9.52858090e-01 3.00146360e-03]\n",
      " [3.62659916e-02 8.90131593e-01]\n",
      " [6.83583831e-03 9.96110260e-01]\n",
      " [9.00803149e-01 3.51514434e-03]\n",
      " [1.04035498e-04 9.96728957e-01]\n",
      " [1.12233707e-03 9.83263254e-01]\n",
      " [9.74583924e-01 3.69816646e-02]\n",
      " [6.22474015e-01 1.41569793e-01]\n",
      " [4.89828410e-04 5.15134871e-01]\n",
      " [2.07182020e-02 8.68212044e-01]\n",
      " [1.91010985e-09 9.98954535e-01]\n",
      " [8.47085752e-03 8.01891744e-01]\n",
      " [7.09104817e-03 8.88678432e-01]\n",
      " [1.10493034e-01 3.61911625e-01]\n",
      " [6.14322344e-05 9.99357104e-01]\n",
      " [6.21529043e-01 6.03921354e-01]\n",
      " [1.81590598e-02 9.57554579e-01]\n",
      " [4.10621539e-02 7.41714120e-01]\n",
      " [7.89987206e-01 1.57903254e-01]\n",
      " [2.06571422e-05 8.09035361e-01]\n",
      " [3.58907928e-05 5.62801771e-02]\n",
      " [9.97785747e-01 3.80924321e-03]\n",
      " [9.99359369e-01 3.98471998e-03]\n",
      " [9.82958436e-01 4.24435474e-02]\n",
      " [6.70404464e-04 2.54559547e-01]\n",
      " [2.93805260e-05 7.06954420e-01]\n",
      " [2.42726058e-02 4.79877949e-01]\n",
      " [9.69167352e-01 6.94307871e-03]\n",
      " [1.12801939e-01 7.23872185e-01]\n",
      " [8.98114755e-04 9.56886530e-01]\n",
      " [9.99901295e-01 2.10520439e-03]\n",
      " [1.72663084e-03 8.70858610e-01]\n",
      " [1.79389536e-01 6.62545741e-01]\n",
      " [9.18388724e-01 1.98227793e-01]\n",
      " [6.63867518e-02 8.62319410e-01]\n",
      " [2.88029499e-02 5.26295304e-01]\n",
      " [4.63435473e-03 5.76994181e-01]\n",
      " [8.97115842e-02 9.30478871e-01]\n",
      " [3.18653104e-09 9.99802589e-01]\n",
      " [8.04447755e-03 8.11405256e-02]\n",
      " [9.99810398e-01 1.41505734e-03]\n",
      " [4.77305293e-04 8.53708386e-01]\n",
      " [1.44038734e-03 9.85799074e-01]\n",
      " [2.32588756e-03 7.37380981e-01]\n",
      " [9.93934095e-01 4.14157566e-03]\n",
      " [9.92448747e-01 7.45042833e-03]\n",
      " [8.97115842e-02 9.30478871e-01]\n",
      " [1.00000000e+00 1.13181152e-07]\n",
      " [9.99720275e-01 3.85385007e-04]\n",
      " [2.55619716e-06 6.15075231e-01]\n",
      " [6.68060209e-04 9.91250217e-01]\n",
      " [8.47082219e-07 9.99729872e-01]\n",
      " [9.99999940e-01 6.29702356e-07]\n",
      " [9.99999881e-01 2.22992003e-05]\n",
      " [4.80111623e-07 5.49041294e-02]\n",
      " [8.98114755e-04 9.56886530e-01]\n",
      " [9.99179244e-01 5.56600979e-03]\n",
      " [9.63238720e-03 6.90214336e-01]\n",
      " [9.68966484e-01 3.57878618e-02]\n",
      " [7.95672386e-05 9.96538043e-01]\n",
      " [2.87350714e-02 2.39509448e-01]\n",
      " [4.36815888e-01 4.03398812e-01]\n",
      " [8.68872821e-01 1.62715599e-01]\n",
      " [9.94934142e-03 6.05161965e-01]\n",
      " [2.10546097e-03 3.70538056e-01]\n",
      " [1.20068081e-02 9.15655196e-01]\n",
      " [7.57324025e-02 7.54999161e-01]\n",
      " [9.96307552e-01 1.86838787e-02]\n",
      " [9.95744169e-01 7.67041463e-03]\n",
      " [9.99760747e-01 6.52137795e-04]\n",
      " [9.97426748e-01 1.75574992e-03]\n",
      " [8.71031359e-02 9.58227217e-01]\n",
      " [9.99981761e-01 9.81776466e-05]\n",
      " [3.41768563e-02 7.80970573e-01]\n",
      " [2.05454681e-10 9.99994099e-01]\n",
      " [3.71934730e-03 7.42680728e-01]\n",
      " [9.80827332e-01 6.08864836e-02]\n",
      " [1.00000000e+00 5.26608460e-07]\n",
      " [9.55833197e-01 2.82623135e-02]\n",
      " [9.28504944e-01 2.64088400e-02]\n",
      " [2.31765881e-02 9.46770906e-01]\n",
      " [3.16607095e-02 9.88241076e-01]\n",
      " [2.05016788e-02 2.88831085e-01]\n",
      " [1.51313073e-03 5.60869753e-01]\n",
      " [3.04057479e-01 5.37442625e-01]\n",
      " [1.64551046e-02 6.56395972e-01]\n",
      " [9.82842743e-01 2.58600730e-02]\n",
      " [7.95672386e-05 9.96538043e-01]\n",
      " [9.89266098e-01 1.74033009e-02]\n",
      " [1.00000000e+00 1.48680712e-08]\n",
      " [9.77816641e-01 1.51109025e-02]\n",
      " [3.04057479e-01 5.37442625e-01]\n",
      " [9.99999404e-01 8.37100728e-04]\n",
      " [1.19967060e-03 9.78841603e-01]\n",
      " [1.37261197e-01 1.43715933e-01]\n",
      " [6.85851148e-04 9.77986932e-01]\n",
      " [2.00981982e-02 8.27179372e-01]\n",
      " [3.06162350e-02 9.68021333e-01]\n",
      " [6.07571099e-03 9.75798070e-01]\n",
      " [4.67065990e-01 8.22639346e-01]\n",
      " [7.68204033e-03 6.95336998e-01]\n",
      " [9.99691188e-01 5.39603294e-04]\n",
      " [1.08766789e-02 9.90192711e-01]\n",
      " [1.00000000e+00 9.64740796e-15]\n",
      " [9.99981165e-01 1.34213569e-05]\n",
      " [8.98114755e-04 9.56886530e-01]\n",
      " [6.56990945e-01 2.35471547e-01]\n",
      " [2.89533615e-01 9.59647715e-01]\n",
      " [1.44038734e-03 9.85799074e-01]\n",
      " [4.89828410e-04 5.15134871e-01]\n",
      " [5.66293346e-03 8.40770721e-01]\n",
      " [1.00000000e+00 5.67367811e-12]\n",
      " [7.84340873e-03 6.70813799e-01]\n",
      " [8.56067896e-01 1.68747351e-01]\n",
      " [8.25878859e-01 1.75543740e-01]\n",
      " [3.16606946e-02 9.88241076e-01]\n",
      " [7.06939027e-04 9.76778030e-01]\n",
      " [9.92504973e-03 9.09180403e-01]\n",
      " [1.00000000e+00 3.69265626e-13]\n",
      " [9.89888549e-01 1.83234029e-02]\n",
      " [1.00000000e+00 7.12849873e-21]\n",
      " [1.63629912e-02 9.06594515e-01]\n",
      " [6.30328759e-06 9.95818973e-01]\n",
      " [9.92457390e-01 2.51025930e-02]\n",
      " [1.44038734e-03 9.85799074e-01]\n",
      " [3.39692123e-02 9.13601458e-01]\n",
      " [9.87742543e-01 6.80461805e-03]\n",
      " [8.01415518e-02 8.03913593e-01]\n",
      " [9.47496474e-01 2.93567255e-02]\n",
      " [2.02549083e-04 9.07595396e-01]\n",
      " [2.24588366e-05 4.35532540e-01]\n",
      " [9.91473734e-01 1.39644854e-02]\n",
      " [2.05454681e-10 9.99994099e-01]\n",
      " [4.80111623e-07 5.49041294e-02]\n",
      " [9.99676168e-01 1.77788956e-03]\n",
      " [8.32538128e-01 1.58015996e-01]\n",
      " [7.95672386e-05 9.96538043e-01]\n",
      " [7.95672386e-05 9.96538043e-01]\n",
      " [1.45688802e-01 9.43581820e-01]\n",
      " [3.96121532e-01 2.30575651e-01]\n",
      " [1.00000000e+00 2.90041022e-14]\n",
      " [9.99918640e-01 2.31489685e-04]\n",
      " [4.53406498e-02 8.14434886e-01]\n",
      " [9.79230940e-01 6.56351000e-02]\n",
      " [9.88357365e-01 3.54871415e-02]\n",
      " [9.99790430e-01 5.95323392e-04]\n",
      " [9.66144919e-01 3.10407802e-02]\n",
      " [1.32400990e-02 4.35210347e-01]\n",
      " [1.45688802e-01 9.43581820e-01]\n",
      " [9.66301918e-01 1.44798309e-01]\n",
      " [5.81441100e-08 9.10024345e-02]\n",
      " [6.93825960e-01 2.12199502e-02]\n",
      " [1.72663084e-03 8.70858610e-01]\n",
      " [9.39876020e-01 4.92759570e-02]\n",
      " [1.32400990e-02 4.35210347e-01]\n",
      " [1.31388137e-04 9.97865975e-01]\n",
      " [6.92701936e-02 9.56460953e-01]\n",
      " [3.72111559e-01 2.55029555e-02]\n",
      " [8.11809441e-05 9.99150574e-01]\n",
      " [4.43004351e-03 7.36666143e-01]\n",
      " [8.97115842e-02 9.30478871e-01]\n",
      " [8.13481808e-02 9.68542695e-01]\n",
      " [9.96810317e-01 1.49634322e-02]\n",
      " [9.99992967e-01 7.55463589e-06]\n",
      " [1.37940664e-02 2.36168742e-01]\n",
      " [9.35324192e-01 1.83096945e-01]\n",
      " [9.89898145e-01 1.44663462e-02]\n",
      " [9.71659541e-01 6.61008134e-02]\n",
      " [9.43684280e-01 2.56633729e-01]\n",
      " [2.90979375e-03 8.61856282e-01]\n",
      " [9.98080432e-01 2.86989869e-03]\n",
      " [9.90065634e-01 6.90784827e-02]\n",
      " [3.82012135e-04 8.92377853e-01]\n",
      " [1.12763820e-02 7.17008412e-01]\n",
      " [5.78663952e-04 6.29906237e-01]\n",
      " [3.41768563e-02 7.80970573e-01]\n",
      " [9.28779840e-01 1.15911491e-01]\n",
      " [2.10546399e-03 3.70537817e-01]\n",
      " [1.37771756e-04 9.77355957e-01]\n",
      " [5.74739603e-03 6.03247404e-01]\n",
      " [9.99981284e-01 2.75423256e-04]\n",
      " [7.95826316e-03 8.73667717e-01]\n",
      " [8.69274318e-01 1.71216011e-01]\n",
      " [9.56029356e-01 1.55444629e-03]\n",
      " [5.78240352e-03 7.41976738e-01]\n",
      " [6.30328759e-06 9.95818973e-01]\n",
      " [9.97549832e-01 2.11765561e-02]\n",
      " [1.20068081e-02 9.15655196e-01]\n",
      " [9.98267651e-01 1.10882102e-02]\n",
      " [9.99729574e-01 3.11066560e-03]\n",
      " [7.42099015e-04 6.81683958e-01]\n",
      " [9.82644737e-01 2.49403231e-02]\n",
      " [3.41768563e-02 7.80970573e-01]\n",
      " [2.90529267e-03 9.99733567e-01]\n",
      " [5.01484331e-03 4.98424172e-01]\n",
      " [1.42809227e-01 2.30754688e-01]\n",
      " [9.69291389e-01 4.84648794e-02]\n",
      " [1.61087979e-02 9.48004186e-01]\n",
      " [2.02549083e-04 9.07595396e-01]\n",
      " [1.60658988e-03 9.30721283e-01]\n",
      " [6.24123275e-01 2.72311687e-01]\n",
      " [4.57630176e-06 7.19428837e-01]\n",
      " [2.24588366e-05 4.35532540e-01]\n",
      " [1.03415493e-02 5.39070331e-02]\n",
      " [1.60658988e-03 9.30721283e-01]\n",
      " [3.39692123e-02 9.13601458e-01]\n",
      " [2.31765881e-02 9.46770906e-01]\n",
      " [1.74760222e-02 7.83659577e-01]\n",
      " [5.25185699e-03 7.31201947e-01]\n",
      " [1.56754249e-04 9.26468551e-01]\n",
      " [7.41822541e-01 1.19506039e-01]\n",
      " [9.05443132e-01 1.53747216e-01]\n",
      " [9.99987841e-01 4.41926852e-04]\n",
      " [9.96888638e-01 5.43731265e-03]\n",
      " [3.36551550e-03 9.20011699e-01]\n",
      " [8.13481808e-02 9.68542695e-01]\n",
      " [9.21736538e-01 4.03293192e-01]\n",
      " [1.15534514e-01 6.73476338e-01]\n",
      " [9.98499632e-01 8.95035104e-04]\n",
      " [9.99999940e-01 8.01548651e-07]\n",
      " [3.71934730e-03 7.42680728e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87       198\n",
      "           1       0.83      0.94      0.88       196\n",
      "\n",
      "    accuracy                           0.88       394\n",
      "   macro avg       0.88      0.88      0.88       394\n",
      "weighted avg       0.88      0.88      0.88       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
